{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a2feca",
   "metadata": {},
   "source": [
    "\n",
    "# E09 - Recommender System\n",
    "\n",
    "### Çoban, Ömer Furkan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffd2afd",
   "metadata": {},
   "source": [
    "\n",
    "# Task 1: Similarity Analysis\n",
    "\n",
    "In this task, we aim to compare scientific papers based on their abstracts. We will fetch the data directly from the web, clean it, and then apply similarity metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10fc139",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Scrape Abstracts from arXiv\n",
    "We use the `requests` library to fetch the HTML content of the provided arXiv URLs. Then, we use `BeautifulSoup` to parse the HTML and extract the **Title** (inside `h1` tag with class `title`) and the **Abstract** (inside `blockquote` tag with class `abstract`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808034f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping abstracts from arXiv...\n",
      "Scraping completed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A large-scale comparative analysis of Coding S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trust in Data Science: Collaboration, Translat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science: Nature and Pitfalls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data science and the art of modelling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A fresh look at introductory data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cloud BI: Future of Business Intelligence in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Effects of Using Business Intelligence Sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Big Data and Business Intelligence: Debunking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Generalized formal model of big data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quality Assurance Technologies of Big Data App...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  A large-scale comparative analysis of Coding S...\n",
       "1  Trust in Data Science: Collaboration, Translat...\n",
       "2                  Data Science: Nature and Pitfalls\n",
       "3              Data science and the art of modelling\n",
       "4          A fresh look at introductory data science\n",
       "5  Cloud BI: Future of Business Intelligence in t...\n",
       "6  The Effects of Using Business Intelligence Sys...\n",
       "7  Big Data and Business Intelligence: Debunking ...\n",
       "8               Generalized formal model of big data\n",
       "9  Quality Assurance Technologies of Big Data App..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import PorterStemmer\n",
    "from IPython.display import display\n",
    "\n",
    "urls = [\n",
    "    \"https://arxiv.org/abs/2007.08978\",\n",
    "    \"https://arxiv.org/abs/2002.03389\",\n",
    "    \"https://arxiv.org/abs/2006.16964\",\n",
    "    \"https://arxiv.org/abs/2007.04095\",\n",
    "    \"https://arxiv.org/abs/2008.00315\",\n",
    "    \"https://arxiv.org/abs/1901.08151\",\n",
    "    \"https://arxiv.org/abs/1901.10555\",\n",
    "    \"https://arxiv.org/abs/1511.03085\",\n",
    "    \"https://arxiv.org/abs/1905.03061\",\n",
    "    \"https://arxiv.org/abs/2002.01759\"\n",
    "]\n",
    "\n",
    "def scrape_arxiv(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract Title\n",
    "        title_tag = soup.find('h1', class_='title')\n",
    "        title = title_tag.text.replace('Title:', '').strip() if title_tag else \"No Title\"\n",
    "        \n",
    "        # Extract Abstract\n",
    "        abstract_tag = soup.find('blockquote', class_='abstract')\n",
    "        abstract = abstract_tag.text.replace('Abstract:', '').strip() if abstract_tag else \"No Abstract\"\n",
    "        \n",
    "        return {\"url\": url, \"title\": title, \"abstract\": abstract}\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return {\"url\": url, \"title\": \"Error\", \"abstract\": \"\"}\n",
    "\n",
    "print(\"Scraping abstracts from arXiv...\")\n",
    "papers_data = [scrape_arxiv(url) for url in urls]\n",
    "df_papers = pd.DataFrame(papers_data)\n",
    "print(\"Scraping completed.\")\n",
    "df_papers[['title']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffabb50",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Preprocessing\n",
    "To ensure accurate similarity calculations, we clean the text data:\n",
    "1.  **Lowercasing**: Convert all text to lower case to treat \"Data\" and \"data\" as the same.\n",
    "2.  **Removing Noise**: Remove punctuation, numbers, and special characters.\n",
    "3.  **Stop Word Removal**: Remove common English words (e.g., \"the\", \"is\", \"at\") that do not carry significant meaning.\n",
    "4.  **Stemming**: Reduce words to their root form (e.g., \"learning\" -> \"learn\") using the Porter Stemmer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5def2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>processed_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A large-scale comparative analysis of Coding S...</td>\n",
       "      <td>background meet grow industri demand data scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trust in Data Science: Collaboration, Translat...</td>\n",
       "      <td>trustworthi data scienc system appli realworld...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science: Nature and Pitfalls</td>\n",
       "      <td>data scienc creat excit trend controversi crit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data science and the art of modelling</td>\n",
       "      <td>datacentr enthusiasm grow strong varieti domai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A fresh look at introductory data science</td>\n",
       "      <td>prolifer vast quantiti dataset larg complex na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  A large-scale comparative analysis of Coding S...   \n",
       "1  Trust in Data Science: Collaboration, Translat...   \n",
       "2                  Data Science: Nature and Pitfalls   \n",
       "3              Data science and the art of modelling   \n",
       "4          A fresh look at introductory data science   \n",
       "\n",
       "                                  processed_abstract  \n",
       "0  background meet grow industri demand data scie...  \n",
       "1  trustworthi data scienc system appli realworld...  \n",
       "2  data scienc creat excit trend controversi crit...  \n",
       "3  datacentr enthusiasm grow strong varieti domai...  \n",
       "4  prolifer vast quantiti dataset larg complex na...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load Stop Words\n",
    "try:\n",
    "    with open('all_stop_words.txt', 'r') as f:\n",
    "        stop_words = set(f.read().split())\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: 'all_stop_words.txt' not found. Creating empty set.\")\n",
    "    stop_words = set()\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special chars and numbers (keep only letters and spaces)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize\n",
    "    words = text.split()\n",
    "    # Remove stop words and stem\n",
    "    words = [stemmer.stem(w) for w in words if w not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df_papers['processed_abstract'] = df_papers['abstract'].apply(preprocess_text)\n",
    "df_papers[['title', 'processed_abstract']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a9472",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Similarity Calculations\n",
    "We use two different metrics to calculate similarity between papers:\n",
    "*   **Jaccard Similarity**: Measures the overlap between the sets of unique words in two documents.\n",
    "*   **Cosine Similarity**: Measures the cosine of the angle between two TF-IDF vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f681cfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrices calculated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Jaccard Similarity\n",
    "def get_jaccard_similarity(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    if len(a) + len(b) - len(c) == 0:\n",
    "        return 0.0\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "# Compute Jaccard Matrix\n",
    "n = len(df_papers)\n",
    "jaccard_matrix = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        jaccard_matrix[i, j] = get_jaccard_similarity(df_papers.iloc[i]['processed_abstract'], df_papers.iloc[j]['processed_abstract'])\n",
    "\n",
    "df_jaccard = pd.DataFrame(jaccard_matrix, index=df_papers['title'], columns=df_papers['title'])\n",
    "\n",
    "# Cosine Similarity using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df_papers['processed_abstract'])\n",
    "cosine_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "df_cosine = pd.DataFrame(cosine_matrix, index=df_papers['title'], columns=df_papers['title'])\n",
    "\n",
    "print(\"Similarity matrices calculated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fbac67",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Results: Most Similar Papers\n",
    "We present the results in a readable table format, identifying the most similar paper for each entry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583c011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Jaccard Similarity Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper</th>\n",
       "      <th>Most Similar Paper</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A fresh look at introductory data science</td>\n",
       "      <td>Quality Assurance Technologies of Big Data App...</td>\n",
       "      <td>0.089552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quality Assurance Technologies of Big Data App...</td>\n",
       "      <td>A fresh look at introductory data science</td>\n",
       "      <td>0.089552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science: Nature and Pitfalls</td>\n",
       "      <td>Big Data and Business Intelligence: Debunking ...</td>\n",
       "      <td>0.075758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Big Data and Business Intelligence: Debunking ...</td>\n",
       "      <td>Data Science: Nature and Pitfalls</td>\n",
       "      <td>0.075758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Effects of Using Business Intelligence Sys...</td>\n",
       "      <td>Generalized formal model of big data</td>\n",
       "      <td>0.073684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Generalized formal model of big data</td>\n",
       "      <td>The Effects of Using Business Intelligence Sys...</td>\n",
       "      <td>0.073684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trust in Data Science: Collaboration, Translat...</td>\n",
       "      <td>A fresh look at introductory data science</td>\n",
       "      <td>0.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data science and the art of modelling</td>\n",
       "      <td>Data Science: Nature and Pitfalls</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cloud BI: Future of Business Intelligence in t...</td>\n",
       "      <td>The Effects of Using Business Intelligence Sys...</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A large-scale comparative analysis of Coding S...</td>\n",
       "      <td>A fresh look at introductory data science</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Paper  \\\n",
       "4          A fresh look at introductory data science   \n",
       "9  Quality Assurance Technologies of Big Data App...   \n",
       "2                  Data Science: Nature and Pitfalls   \n",
       "7  Big Data and Business Intelligence: Debunking ...   \n",
       "6  The Effects of Using Business Intelligence Sys...   \n",
       "8               Generalized formal model of big data   \n",
       "1  Trust in Data Science: Collaboration, Translat...   \n",
       "3              Data science and the art of modelling   \n",
       "5  Cloud BI: Future of Business Intelligence in t...   \n",
       "0  A large-scale comparative analysis of Coding S...   \n",
       "\n",
       "                                  Most Similar Paper     Score  \n",
       "4  Quality Assurance Technologies of Big Data App...  0.089552  \n",
       "9          A fresh look at introductory data science  0.089552  \n",
       "2  Big Data and Business Intelligence: Debunking ...  0.075758  \n",
       "7                  Data Science: Nature and Pitfalls  0.075758  \n",
       "6               Generalized formal model of big data  0.073684  \n",
       "8  The Effects of Using Business Intelligence Sys...  0.073684  \n",
       "1          A fresh look at introductory data science  0.072000  \n",
       "3                  Data Science: Nature and Pitfalls  0.060000  \n",
       "5  The Effects of Using Business Intelligence Sys...  0.058333  \n",
       "0          A fresh look at introductory data science  0.055556  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cosine Similarity Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper</th>\n",
       "      <th>Most Similar Paper</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Big Data and Business Intelligence: Debunking ...</td>\n",
       "      <td>Generalized formal model of big data</td>\n",
       "      <td>0.362810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Generalized formal model of big data</td>\n",
       "      <td>Big Data and Business Intelligence: Debunking ...</td>\n",
       "      <td>0.362810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quality Assurance Technologies of Big Data App...</td>\n",
       "      <td>Generalized formal model of big data</td>\n",
       "      <td>0.341554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trust in Data Science: Collaboration, Translat...</td>\n",
       "      <td>Data Science: Nature and Pitfalls</td>\n",
       "      <td>0.290747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science: Nature and Pitfalls</td>\n",
       "      <td>Trust in Data Science: Collaboration, Translat...</td>\n",
       "      <td>0.290747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A fresh look at introductory data science</td>\n",
       "      <td>Data Science: Nature and Pitfalls</td>\n",
       "      <td>0.236506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A large-scale comparative analysis of Coding S...</td>\n",
       "      <td>Trust in Data Science: Collaboration, Translat...</td>\n",
       "      <td>0.221797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cloud BI: Future of Business Intelligence in t...</td>\n",
       "      <td>The Effects of Using Business Intelligence Sys...</td>\n",
       "      <td>0.188607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Effects of Using Business Intelligence Sys...</td>\n",
       "      <td>Cloud BI: Future of Business Intelligence in t...</td>\n",
       "      <td>0.188607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data science and the art of modelling</td>\n",
       "      <td>Trust in Data Science: Collaboration, Translat...</td>\n",
       "      <td>0.162726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Paper  \\\n",
       "7  Big Data and Business Intelligence: Debunking ...   \n",
       "8               Generalized formal model of big data   \n",
       "9  Quality Assurance Technologies of Big Data App...   \n",
       "1  Trust in Data Science: Collaboration, Translat...   \n",
       "2                  Data Science: Nature and Pitfalls   \n",
       "4          A fresh look at introductory data science   \n",
       "0  A large-scale comparative analysis of Coding S...   \n",
       "5  Cloud BI: Future of Business Intelligence in t...   \n",
       "6  The Effects of Using Business Intelligence Sys...   \n",
       "3              Data science and the art of modelling   \n",
       "\n",
       "                                  Most Similar Paper     Score  \n",
       "7               Generalized formal model of big data  0.362810  \n",
       "8  Big Data and Business Intelligence: Debunking ...  0.362810  \n",
       "9               Generalized formal model of big data  0.341554  \n",
       "1                  Data Science: Nature and Pitfalls  0.290747  \n",
       "2  Trust in Data Science: Collaboration, Translat...  0.290747  \n",
       "4                  Data Science: Nature and Pitfalls  0.236506  \n",
       "0  Trust in Data Science: Collaboration, Translat...  0.221797  \n",
       "5  The Effects of Using Business Intelligence Sys...  0.188607  \n",
       "6  Cloud BI: Future of Business Intelligence in t...  0.188607  \n",
       "3  Trust in Data Science: Collaboration, Translat...  0.162726  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def get_most_similar_df(sim_df):\n",
    "    # Mask diagonal explicitly to avoid self-matching\n",
    "    np.fill_diagonal(sim_df.values, -np.inf)\n",
    "    \n",
    "    results = []\n",
    "    for title in sim_df.index:\n",
    "        most_sim_title = sim_df.loc[title].idxmax()\n",
    "        score = sim_df.loc[title].max()\n",
    "        results.append({\n",
    "            \"Paper\": title,\n",
    "            \"Most Similar Paper\": most_sim_title,\n",
    "            \"Score\": score\n",
    "        })\n",
    "    return pd.DataFrame(results).sort_values(\"Score\", ascending=False)\n",
    "\n",
    "print(\"--- Jaccard Similarity Results ---\")\n",
    "display(get_most_similar_df(df_jaccard.copy()))\n",
    "\n",
    "print(\"\\n--- Cosine Similarity Results ---\")\n",
    "display(get_most_similar_df(df_cosine.copy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cdbfb4",
   "metadata": {},
   "source": [
    "\n",
    "# Task 2: Movie Recommendation\n",
    "\n",
    "In this task, we implement a recommender system using User-based Collaborative Filtering. We start with a SQL database dump, parse it into a usable format, and then build the recommendation engine to predict missing ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cae88d",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Parse SQL & Generate CSVs\n",
    "The data is provided in a PostgreSQL dump file (`ratingdb_postgresql.sql`). We use Regular Expressions (`re`) to parse the `INSERT` statements and extract data for:\n",
    "*   **Movies**: ID, Title, Release Year, Director.\n",
    "*   **Reviewers**: ID, Name.\n",
    "*   **Ratings**: Reviewer ID, Movie ID, Stars, Date.\n",
    "\n",
    "We then save these structured datasets as CSV files for easier loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7300f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created movies.csv\n",
      "Created reviewers.csv\n",
      "Created ratings.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read SQL file\n",
    "sql_file = 'ratingdb_postgresql.sql'\n",
    "try:\n",
    "    with open(sql_file, 'r') as f:\n",
    "        sql_content = f.read()\n",
    "    \n",
    "    # Extract Movies\n",
    "    movies = []\n",
    "    movie_matches = re.findall(r\"INSERT INTO movie \\(m_id,title,release_year,director\\) VALUES \\((\\d+),'([^']*)',(\\d+),([^)]*)\\);\", sql_content)\n",
    "    for match in movie_matches:\n",
    "        m_id, title, year, director = match\n",
    "        director = director.strip(\"'\") if director != 'NULL' else None\n",
    "        movies.append({'m_id': int(m_id), 'title': title, 'year': int(year), 'director': director})\n",
    "    \n",
    "    df_movies_extracted = pd.DataFrame(movies)\n",
    "    df_movies_extracted.to_csv('movies.csv', index=False)\n",
    "    print(\"Created movies.csv\")\n",
    "    \n",
    "    # Extract Reviewers\n",
    "    reviewers = []\n",
    "    reviewer_matches = re.findall(r\"INSERT INTO reviewer \\(r_id,reviewer_name\\) VALUES \\((\\d+),'([^']*)'\\);\", sql_content)\n",
    "    for match in reviewer_matches:\n",
    "        r_id, name = match\n",
    "        reviewers.append({'r_id': int(r_id), 'reviewer_name': name})\n",
    "    \n",
    "    df_reviewers_extracted = pd.DataFrame(reviewers)\n",
    "    df_reviewers_extracted.to_csv('reviewers.csv', index=False)\n",
    "    print(\"Created reviewers.csv\")\n",
    "    \n",
    "    # Extract Ratings\n",
    "    ratings = []\n",
    "    rating_matches = re.findall(r\"INSERT INTO rating \\(r_id,m_id,stars,rating_date\\) VALUES \\((\\d+),(\\d+),(\\d+),([^)]*)\\);\", sql_content)\n",
    "    for match in rating_matches:\n",
    "        r_id, m_id, stars, date = match\n",
    "        date = date.strip(\"'\") if date != 'NULL' else None\n",
    "        ratings.append({'r_id': int(r_id), 'm_id': int(m_id), 'stars': int(stars), 'date': date})\n",
    "    \n",
    "    df_ratings_extracted = pd.DataFrame(ratings)\n",
    "    df_ratings_extracted.to_csv('ratings.csv', index=False)\n",
    "    print(\"Created ratings.csv\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {sql_file} not found. Utilizing existing CSVs if available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd1a06",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Prepare Rating Matrix (Pivot Table)\n",
    "We merge the extracted CSVs into a single DataFrame and then create a Pivot Table.\n",
    "*   **Rows**: Reviewers\n",
    "*   **Columns**: Movies\n",
    "*   **Values**: Ratings (Stars)\n",
    "\n",
    "This matrix is the foundation for Collaborative Filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc712600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating Matrix Shape: (8, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>Gone with the Wind</th>\n",
       "      <th>Star Wars</th>\n",
       "      <th>The Sound of Music</th>\n",
       "      <th>E.T.</th>\n",
       "      <th>Titanic</th>\n",
       "      <th>Snow White</th>\n",
       "      <th>Avatar</th>\n",
       "      <th>Raiders of the Lost Ark</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewer_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ashley White</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brittany Harris</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris Jackson</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniel Lewis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elizabeth Thomas</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James Cameron</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mike Anderson</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sarah Martinez</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "title             Gone with the Wind  Star Wars  The Sound of Music  E.T.  \\\n",
       "reviewer_name                                                               \n",
       "Ashley White                     NaN        NaN                 NaN   3.0   \n",
       "Brittany Harris                  NaN        NaN                 2.0   NaN   \n",
       "Chris Jackson                    NaN        NaN                 3.0   2.0   \n",
       "Daniel Lewis                     NaN        NaN                 NaN   NaN   \n",
       "Elizabeth Thomas                 NaN        NaN                 NaN   NaN   \n",
       "James Cameron                    NaN        NaN                 NaN   NaN   \n",
       "Mike Anderson                    3.0        NaN                 NaN   NaN   \n",
       "Sarah Martinez                   3.0        NaN                 NaN   NaN   \n",
       "\n",
       "title             Titanic  Snow White  Avatar  Raiders of the Lost Ark  \n",
       "reviewer_name                                                           \n",
       "Ashley White          NaN         NaN     NaN                      NaN  \n",
       "Brittany Harris       NaN         NaN     NaN                      3.0  \n",
       "Chris Jackson         NaN         NaN     NaN                      4.0  \n",
       "Daniel Lewis          NaN         4.0     NaN                      NaN  \n",
       "Elizabeth Thomas      NaN         5.0     3.0                      NaN  \n",
       "James Cameron         NaN         NaN     5.0                      NaN  \n",
       "Mike Anderson         NaN         NaN     NaN                      NaN  \n",
       "Sarah Martinez        NaN         NaN     NaN                      NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_movies = pd.read_csv('movies.csv')\n",
    "df_ratings = pd.read_csv('ratings.csv')\n",
    "df_reviewers = pd.read_csv('reviewers.csv')\n",
    "\n",
    "# Merge\n",
    "df = pd.merge(df_ratings, df_movies, on='m_id')\n",
    "df = pd.merge(df, df_reviewers, on='r_id')\n",
    "\n",
    "# Pivot Table (Users x Movies)\n",
    "df_pivot = df.pivot_table(index='reviewer_name', columns='title', values='stars', aggfunc='mean')\n",
    "\n",
    "# Ensure all movies are columns\n",
    "all_movie_titles = df_movies['title'].unique()\n",
    "df_pivot = df_pivot.reindex(columns=all_movie_titles)\n",
    "\n",
    "print(\"Rating Matrix Shape:\", df_pivot.shape)\n",
    "df_pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3ba16",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Collaborative Filtering (User-Based)\n",
    "We employ **User-based Collaborative Filtering**. The core idea is that users who agreed in the past (gave similar ratings) will agree in the future.\n",
    "\n",
    "1.  **Centering**: Different users have different baseline ratings (some are generous, some critical). We normalize this by subtracting each user's mean rating from their scores.\n",
    "2.  **Cosine Similarity**: We calculate the similarity between all pairs of users using the centered ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6aab532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities calculated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Center the ratings (subtract user mean)\n",
    "df_centered = df_pivot.apply(lambda x: x - x.mean(), axis=1).fillna(0)\n",
    "\n",
    "# User Similarity\n",
    "user_sim = cosine_similarity(df_centered)\n",
    "user_sim_df = pd.DataFrame(user_sim, index=df_pivot.index, columns=df_pivot.index)\n",
    "\n",
    "# Item Similarity (Transposed)\n",
    "item_sim = cosine_similarity(df_centered.T)\n",
    "item_sim_df = pd.DataFrame(item_sim, index=df_pivot.columns, columns=df_pivot.columns)\n",
    "\n",
    "print(\"Similarities calculated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f5aeaa",
   "metadata": {},
   "source": [
    "\n",
    "## Questions\n",
    "\n",
    "**1. Which algorithm did you select and why?**\n",
    "I selected **User-based Collaborative Filtering with Centered Cosine Similarity**. This method is effective because it:\n",
    "*   **Handles Bias**: Centering removes individual rating biases (optimism/pessimism).\n",
    "*   **Leverages Community**: It uses the collective wisdom of similar users to predict unknown preferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466f4fd",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Identify Most Similar Movies & Users\n",
    "Using the calculated similarity matrices, we can now answer:\n",
    "*   Which two movies are most similar based on user ratings?\n",
    "*   Which two users have the most similar taste?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "085dadcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar movies: 'Gone with the Wind' and 'Star Wars' (Score: 0.0000)\n",
      "Most similar users: 'Brittany Harris' and 'Chris Jackson' (Score: 0.5000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_most_similar_pair(sim_df):\n",
    "    # Mask indices to avoid self-comparison\n",
    "    # We use a copy to avoid checking diagonal\n",
    "    sim_masked = sim_df.copy()\n",
    "    np.fill_diagonal(sim_masked.values, -np.inf)\n",
    "    \n",
    "    sim_stack = sim_masked.stack()\n",
    "    return sim_stack.idxmax(), sim_stack.max()\n",
    "\n",
    "# Similar Movies\n",
    "movie_pair, movie_score = get_most_similar_pair(item_sim_df)\n",
    "print(f\"Most similar movies: '{movie_pair[0]}' and '{movie_pair[1]}' (Score: {movie_score:.4f})\")\n",
    "\n",
    "# Similar Users\n",
    "user_pair, user_score = get_most_similar_pair(user_sim_df)\n",
    "print(f\"Most similar users: '{user_pair[0]}' and '{user_pair[1]}' (Score: {user_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "result_explanation",
   "metadata": {},
   "source": [
    "\n",
    "**Most Similar Users (Score: 0.5000)**\n",
    "*   **Brittany Harris** and **Chris Jackson** have a positive correlation because they both rated 'Raiders of the Lost Ark' above their personal averages.\n",
    "\n",
    "**Most Similar Movies (Score: 0.0000)**\n",
    "*   The score of **0.0** is correct for this dataset.\n",
    "*   There are **no movie pairs** with a positive correlation in this small dataset.\n",
    "*   'Star Wars' has no ratings, resulting in a 0.0 similarity with everything.\n",
    "*   Since all other distinct pairs have negative correlations, 0.0 becomes the maximum score (and thus 'Gone with the Wind' and 'Star Wars' are returned alphabetically/by index as the best match).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a145d9b",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Personal Recommendations\n",
    "Finally, we put the recommender to the test.\n",
    "1.  **Create Profile**: Add a \"My Profile\" user with specific ratings (e.g., liking *Star Wars*).\n",
    "2.  **Re-calculate Similarities**: Update the user similarity matrix to include this new profile.\n",
    "3.  **Predict Ratings**: Estimate ratings for movies the profile hasn't seen yet (e.g., *E.T.*, *Titanic*) by taking a weighted average of ratings from the most similar users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288a8d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Predictions for My Profile ---\n",
      "Predicted rating for 'E.T.': 2.00\n",
      "Predicted rating for 'Titanic': 4.67\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create My Profile\n",
    "my_ratings = pd.Series(name='My Profile', dtype=float)\n",
    "my_ratings['Star Wars'] = 5.0\n",
    "my_ratings['Raiders of the Lost Ark'] = 5.0\n",
    "my_ratings['Avatar'] = 4.0\n",
    "\n",
    "# Add to Pivot\n",
    "df_pivot_with_me = pd.concat([df_pivot, my_ratings.to_frame().T])\n",
    "\n",
    "# Re-calculate similarities\n",
    "df_centered_with_me = df_pivot_with_me.apply(lambda x: x - x.mean(), axis=1).fillna(0)\n",
    "user_sim_with_me = cosine_similarity(df_centered_with_me)\n",
    "user_sim_with_me_df = pd.DataFrame(user_sim_with_me, index=df_pivot_with_me.index, columns=df_pivot_with_me.index)\n",
    "\n",
    "def predict_rating(user, item, pivot_df, sim_df):\n",
    "    # Get similar users\n",
    "    user_similarities = sim_df[user].sort_values(ascending=False).drop(user)\n",
    "    # Get ratings for the item\n",
    "    item_ratings = pivot_df[item].drop(user).dropna()\n",
    "    \n",
    "    # Intersection\n",
    "    relevant_users = item_ratings.index.intersection(user_similarities.index)\n",
    "    \n",
    "    if len(relevant_users) == 0:\n",
    "        return pivot_df.loc[user].mean()\n",
    "        \n",
    "    weights = user_similarities[relevant_users]\n",
    "    if weights.sum() == 0:\n",
    "        return pivot_df.loc[user].mean()\n",
    "        \n",
    "    ratings = item_ratings[relevant_users]\n",
    "    \n",
    "    prediction = np.dot(weights, ratings) / weights.sum()\n",
    "    return prediction\n",
    "\n",
    "# Predict for unrated movies\n",
    "target_movies = ['E.T.', 'Titanic']\n",
    "print(\"--- Predictions for My Profile ---\")\n",
    "for movie in target_movies:\n",
    "    pred = predict_rating('My Profile', movie, df_pivot_with_me, user_sim_with_me_df)\n",
    "    print(f\"Predicted rating for '{movie}': {pred:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
